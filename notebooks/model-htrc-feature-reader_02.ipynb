{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3622c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from htrc_features import FeatureReader\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3cb7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_htrc_page_data(document):\n",
    "    fr = FeatureReader([document])\n",
    "    vol = next(fr.volumes())\n",
    "    ptc = vol.tokenlist(pos=False, case=False).reset_index().drop(['section'], axis=1)\n",
    "    page_list = set(ptc['page'])\n",
    "    \n",
    "    # extract tokens by page \n",
    "    tokens=list()\n",
    "    for page in page_list:\n",
    "        page_data = str()\n",
    "        \n",
    "        # operate on each token\n",
    "        for page_tokens in ptc.loc[ptc['page'] == page].iterrows():\n",
    "            if page_tokens[1][1].isalpha():\n",
    "                \n",
    "                # deal with frequency count by creating correct number of tokens\n",
    "                page_data += (' '.join([page_tokens[1][1]] * page_tokens[1][2])) + \" \"\n",
    "\n",
    "        tokens.append(page_data.split())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d7fee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# htids for two classes \n",
    "chase_novels = [\"mdp.39015004308212\",\n",
    "                \"mdp.39015024849682\",\n",
    "                \"coo.31924014522449\"]\n",
    "jewett_novels = [\"uc1.32106015388678\",\n",
    "                \"uc2.ark:/13960/t9w08xb8w\",\n",
    "                \"uiug.30112012873441\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbadb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jed/miniforge3/envs/cv/lib/python3.9/site-packages/htrc_features/feature_reader.py:107: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  return df.reset_index().groupby(groups).sum()[['count']]\n"
     ]
    }
   ],
   "source": [
    "page_tokens = get_htrc_page_data(chase_novels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de110206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'about',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'afternoon',\n",
       " 'against',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'all',\n",
       " 'an',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'any',\n",
       " 'any',\n",
       " 'as',\n",
       " 'as',\n",
       " 'as',\n",
       " 'assuming',\n",
       " 'at',\n",
       " 'at',\n",
       " 'aware',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beneath',\n",
       " 'betokened',\n",
       " 'blue',\n",
       " 'bodice',\n",
       " 'body',\n",
       " 'bracket',\n",
       " 'brass',\n",
       " 'breeches',\n",
       " 'broadcloth',\n",
       " 'brown',\n",
       " 'button',\n",
       " 'buttons',\n",
       " 'came',\n",
       " 'carried',\n",
       " 'carried',\n",
       " 'carry',\n",
       " 'chinook',\n",
       " 'chintzes',\n",
       " 'coast',\n",
       " 'coat',\n",
       " 'coat',\n",
       " 'coat',\n",
       " 'collar',\n",
       " 'common',\n",
       " 'confidence',\n",
       " 'corners',\n",
       " 'corners',\n",
       " 'cove',\n",
       " 'cove',\n",
       " 'cove',\n",
       " 'cravat',\n",
       " 'crochet',\n",
       " 'crocketts',\n",
       " 'discover',\n",
       " 'disturbing',\n",
       " 'diverse',\n",
       " 'dowry',\n",
       " 'drawn',\n",
       " 'edging',\n",
       " 'either',\n",
       " 'even',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'far',\n",
       " 'farthest',\n",
       " 'fell',\n",
       " 'fights',\n",
       " 'fine',\n",
       " 'fine',\n",
       " 'flowered',\n",
       " 'fortnight',\n",
       " 'frills',\n",
       " 'from',\n",
       " 'from',\n",
       " 'fumbling',\n",
       " 'future',\n",
       " 'garden',\n",
       " 'habits',\n",
       " 'had',\n",
       " 'had',\n",
       " 'had',\n",
       " 'had',\n",
       " 'had',\n",
       " 'hair',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'he',\n",
       " 'head',\n",
       " 'heart',\n",
       " 'heart',\n",
       " 'her',\n",
       " 'her',\n",
       " 'her',\n",
       " 'her',\n",
       " 'her',\n",
       " 'her',\n",
       " 'her',\n",
       " 'her',\n",
       " 'her',\n",
       " 'herself',\n",
       " 'high',\n",
       " 'him',\n",
       " 'him',\n",
       " 'him',\n",
       " 'him',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'his',\n",
       " 'hook',\n",
       " 'in',\n",
       " 'in',\n",
       " 'in',\n",
       " 'indians',\n",
       " 'inevitably',\n",
       " 'kept',\n",
       " 'knee',\n",
       " 'known',\n",
       " 'lace',\n",
       " 'lace',\n",
       " 'later',\n",
       " 'later',\n",
       " 'lilacs',\n",
       " 'lodestone',\n",
       " 'maine',\n",
       " 'making',\n",
       " 'man',\n",
       " 'massachusetts',\n",
       " 'might',\n",
       " 'mirrors',\n",
       " 'more',\n",
       " 'neck',\n",
       " 'night',\n",
       " 'not',\n",
       " 'oddly',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'of',\n",
       " 'offered',\n",
       " 'on',\n",
       " 'on',\n",
       " 'on',\n",
       " 'on',\n",
       " 'or',\n",
       " 'or',\n",
       " 'other',\n",
       " 'outpost',\n",
       " 'over',\n",
       " 'penetrated',\n",
       " 'perhaps',\n",
       " 'person',\n",
       " 'persuasion',\n",
       " 'pictures',\n",
       " 'place',\n",
       " 'portion',\n",
       " 'recounting',\n",
       " 'room',\n",
       " 'ruffled',\n",
       " 'ruffles',\n",
       " 'salem',\n",
       " 'saturday',\n",
       " 'saturday',\n",
       " 'saturday',\n",
       " 'seemed',\n",
       " 'seemed',\n",
       " 'self',\n",
       " 'shadowy',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'she',\n",
       " 'short',\n",
       " 'shuttle',\n",
       " 'single',\n",
       " 'sleeves',\n",
       " 'snowy',\n",
       " 'so',\n",
       " 'so',\n",
       " 'some',\n",
       " 'stretched',\n",
       " 'substantial',\n",
       " 'syringas',\n",
       " 'tail',\n",
       " 'talked',\n",
       " 'than',\n",
       " 'that',\n",
       " 'that',\n",
       " 'that',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'there',\n",
       " 'thighs',\n",
       " 'though',\n",
       " 'thought',\n",
       " 'thought',\n",
       " 'thoughts',\n",
       " 'tight',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'under',\n",
       " 'unique',\n",
       " 'upstanding',\n",
       " 'variance',\n",
       " 'vases',\n",
       " 'velvet',\n",
       " 'walls',\n",
       " 'wanted',\n",
       " 'was',\n",
       " 'was',\n",
       " 'was',\n",
       " 'was',\n",
       " 'way',\n",
       " 'way',\n",
       " 'well',\n",
       " 'when',\n",
       " 'which',\n",
       " 'which',\n",
       " 'which',\n",
       " 'which',\n",
       " 'which',\n",
       " 'white',\n",
       " 'windows',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'with',\n",
       " 'wore',\n",
       " 'worked',\n",
       " 'world',\n",
       " 'wrapping',\n",
       " 'young']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_tokens[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf6bf863",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [w for p in page_tokens for w in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b699ccc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111201"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a789ddd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['crockett',\n",
       " 'silas',\n",
       " 'atlanta',\n",
       " 'ban',\n",
       " 'bombay',\n",
       " 'boston',\n",
       " 'calcutta',\n",
       " 'canada',\n",
       " 'chicago',\n",
       " 'co']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "760ce372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6836"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.count(\"the\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a848ef52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.count(\"sea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f47599b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.count(\"mother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "771d5cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1748"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.count(\"his\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3abdbe4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.count(\"hers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5249ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
