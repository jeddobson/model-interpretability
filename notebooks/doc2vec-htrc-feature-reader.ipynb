{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade56d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from htrc_features import FeatureReader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import gensim.models.keyedvectors as kv\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924d5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"mdp.39015004308212\",\n",
    "             \"mdp.39015024849682\",\n",
    "             \"coo.31924014522449\",\n",
    "             \"uc1.32106015388678\",\n",
    "             \"uc2.ark:/13960/t9w08xb8w\",\n",
    "             \"uiug.30112012873441\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(document):\n",
    "    fr = FeatureReader([document])\n",
    "    vol = next(fr.volumes())\n",
    "    ptc = vol.tokenlist(pos=False, case=False).reset_index().drop(['section'], axis=1)\n",
    "    page_list = set(ptc['page'])\n",
    "    \n",
    "    rows=list()\n",
    "    for page in page_list:\n",
    "        page_data = str()\n",
    "        \n",
    "        # operate on each token\n",
    "        for page_tokens in ptc.loc[ptc['page'] == page].iterrows():\n",
    "            if page_tokens[1][1].isalpha():\n",
    "                page_data += (' '.join([page_tokens[1][1]] * page_tokens[1][2])) + \" \"\n",
    "\n",
    "        # Doc2Vec needs comma separated list of words\n",
    "        rows.append(page_data.split())\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca18e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = list()\n",
    "for d in documents:\n",
    "    for page in get_pages(d):\n",
    "        pages.append(page)\n",
    "\n",
    "# convert to TaggedDocument\n",
    "tagged_data = [TaggedDocument(words=_d, tags=[str(i)]) for i, _d in enumerate(pages)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d81cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(tagged_data, \n",
    "                dm=1, # operate on \"paragraphs\" (pages) with distributed memory model\n",
    "                vector_size=300, # larger vector size might produce better results\n",
    "                min_count=5, # drop words with very few repetitions\n",
    "                window=150, # larger window size needed because of extracted features\n",
    "                workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11421e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Interview\" the model\n",
    "vocab_size, dim = model.wv.vectors.shape\n",
    "print(\"vocab:\", vocab_size)\n",
    "print(\"depth:\", dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea62d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save word2vec model\n",
    "model.save_word2vec_format(\"../models/doc2vec-htrc-collection.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f44dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite model with KV \n",
    "model =  kv.KeyedVectors.load_word2vec_format(\"../models/doc2vec-htrc-collection.w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb25fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"mother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.most_similar(\"schooner\",topn=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccbd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_terms_pca(term):\n",
    "    neighbor_vectors=list()\n",
    "    neighbor_words=list()\n",
    "\n",
    "    for word, j in model.most_similar(term,topn=15):\n",
    "        neighbor_words.append(word)\n",
    "        neighbor_vectors.append(model[word])\n",
    "   \n",
    "    pca = PCA(n_components=2)\n",
    "    plot_data = pca.fit_transform(neighbor_vectors)\n",
    "    xs, ys = plot_data[:, 0], plot_data[:, 1]\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    plt.clf()\n",
    "    plt.title(\"PCA Neighboring Terms for: \" + term)\n",
    "    plt.style.use('ggplot')\n",
    "    plt.scatter(xs, ys, marker = '^')\n",
    "    for i, w in enumerate(neighbor_words):\n",
    "         plt.annotate(w, xy = (xs[i], ys[i]), xytext = (3, 3),\n",
    "            textcoords = 'offset points', ha = 'left', va = 'top')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_terms_pca(\"father\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
