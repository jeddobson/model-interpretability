{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f8295eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from htrc_features import FeatureReader\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6af5fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_htrc_page_data(document):\n",
    "    fr = FeatureReader([document])\n",
    "    vol = next(fr.volumes())\n",
    "    ptc = vol.tokenlist(pos=False, case=False).reset_index().drop(['section'], axis=1)\n",
    "    page_list = set(ptc['page'])\n",
    "    \n",
    "    # extract tokens by page \n",
    "    tokens=list()\n",
    "    for page in page_list:\n",
    "        page_data = str()\n",
    "        \n",
    "        # operate on each token\n",
    "        for page_tokens in ptc.loc[ptc['page'] == page].iterrows():\n",
    "            if page_tokens[1][1].isalpha():\n",
    "                \n",
    "                # deal with frequency count by creating correct number of tokens\n",
    "                page_data += (' '.join([page_tokens[1][1]] * page_tokens[1][2])) + \" \"\n",
    "\n",
    "        tokens.append(page_data.split())\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7858a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# htids for two classes \n",
    "hard_sf = [\"mdp.39015038888775\", \"pst.000027847633\", \"mdp.39015013517985\", \"mdp.39015020680461\", \"mdp.39015020690858\", \"pst.000029273768\", \"mdp.39015013433738\", \"mdp.39015013534014\", \"mdp.39015012435791\", \"pst.000059688501\"]\n",
    "soft_sf = [\"mdp.39015020645456\", \"mdp.39015003922005\", \"mdp.39015000244775\", \"mdp.39015047597136\", \"ppt.ssfcbz201710000391\", \"mdp.49015000529041\", \"uiug.30112077272364\", \"ppt.ssfcbz201710000347\", \"mdp.49015003071447\", \"inu.30000004080028\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "244ae9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labels for classifier\n",
    "labels = [\"hard\"] * len(hard_sf) + [\"soft\"] * len(soft_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct text for consumption into dtm\n",
    "raw_data = list()\n",
    "for doc in hard_sf + soft_sf:\n",
    "    page_data = get_htrc_page_data(doc)\n",
    "    tokens = ' '.join([w for p in page_data for w in p])\n",
    "    raw_data.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357f8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(input='content',\n",
    "                             stop_words='english',\n",
    "                             strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vec.fit_transform(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = SGDClassifier(tol=None,max_iter=1000,random_state=42).fit(dtm,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e263f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([clf.coef_[0][idx] for idx in np.argsort(clf.coef_[0])[:40]],\n",
    "                  index = [vec.get_feature_names_out()[idx] for idx in np.argsort(clf.coef_[0])[:40]])\n",
    "df.plot(figsize=(20, 5),kind='bar',title='Key Features: Hard',legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98299641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_dist_matrix = 1 - cosine_similarity(dtm)\n",
    "\n",
    "%timeit\n",
    "affprop = AffinityPropagation(random_state=None,affinity=\"precomputed\", max_iter=1000, damping=0.99)\n",
    "affprop.fit(cosine_dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75acbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display clusters\n",
    "for cluster in np.unique(affprop.labels_):\n",
    "    print(cluster,\" \".join(np.array(labels)[(affprop.labels_ == cluster)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31acd334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
